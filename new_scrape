from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium import webdriver
from bs4 import BeautifulSoup as bs4
import pandas as pd
pd.set_option('display.max_rows', 999)
path_to_chromedriver = 'C:/Users/gwhy5/Desktop/python.py/chromedriver.exe' # change path as needed
driver = webdriver.Chrome(executable_path = path_to_chromedriver)
driver.wait = WebDriverWait(driver, 15)
start_url = 'http://games.espn.com/ffl/freeagency?seasonId=2018&leagueId=1495557&teamId=6#seasonId=2018&context=freeagency&view=overview&avail=-1&slotCategoryGroup=null'

driver.get(start_url)
driver.switch_to.frame('disneyid-iframe')
email = driver.find_element_by_css_selector('#did-ui > div > div > section > section > form > section > div:nth-child(1) > div > label > span.input-wrapper > input')
email.send_keys('wiehlgt@mymail.vcu.edu')
password = driver.find_element_by_css_selector('#did-ui > div > div > section > section > form > section > div:nth-child(2) > div > label > span.input-wrapper > input')
password.send_keys('H0tdogdude')
button = driver.find_element_by_css_selector('#did-ui > div > div > section > section > form > section > div.btn-group.touch-print-btn-group-wrapper > button')
button.click()
#Wait until last data in last row is loaded just in case:
driver.wait.until(EC.visibility_of_element_located(
                (By.XPATH, '//*[@id="plyr18823"]/td[18]/nobr/span')))
driver.switch_to_default_content()
#find the all button for all players
all_play_button=driver.find_element_by_css_selector('#ajaxFilterShell > ul:nth-child(6) > li:nth-child(1) > a')
all_play_button.click()
driver.wait.until(EC.visibility_of_element_located(
                (By.XPATH, '//*[@id="plyr18823"]/td[18]/nobr/span')))
#pulls together soup, scrapes tables for text

soup = bs4(driver.page_source, 'html5lib')
table = soup.find(id="playertable_0")
df=pd.read_html(str(table))
#not totally sure why I do this but now it is a list instead of a list of a list
#
for i in range(1,21):
    driver.implicitly_wait(10)
    driver.find_element_by_partial_link_text("NEXT").click() #clicks to the next page to scrape
    sec_soup=bs4(driver.page_source,'html5lib')
    sec_table=sec_soup.find(id="playertable_0")
    sec_df=pd.read_html(str(sec_table))
    sec_df=sec_df[0]
    df.append(sec_df) 
del df[0] # for some reason I get two of the same first table so I'm deleting it
final=pd.concat(df)
final.set_index(0)
print final
